{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.7285  0.6821  0.0634\n",
       "  0.6554  0.5440  0.5240\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.6979  0.7069  0.1149\n",
       "  0.6810  0.7286  0.0737\n",
       "[torch.FloatTensor of size 2x2x3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = Variable(torch.rand(2, 2, 3))\n",
    "m = (A.norm(p=2,dim=2)).view(2,2,1)\n",
    "y=A/m\n",
    "y\n",
    "# x = Variable(A, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(512, 2048, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0  , 0  ,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 0  , 1  ,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 0  , 2  ,.,.) = \n",
       "  0.0000\n",
       "      ... \n",
       "\n",
       "( 0  ,2045,.,.) = \n",
       "  0.4991\n",
       "\n",
       "( 0  ,2046,.,.) = \n",
       "  0.0632\n",
       "\n",
       "( 0  ,2047,.,.) = \n",
       "  0.0842\n",
       "        ⋮  \n",
       "\n",
       "( 1  , 0  ,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 1  , 1  ,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 1  , 2  ,.,.) = \n",
       "  0.0000\n",
       "      ... \n",
       "\n",
       "( 1  ,2045,.,.) = \n",
       "  0.0800\n",
       "\n",
       "( 1  ,2046,.,.) = \n",
       "  0.0810\n",
       "\n",
       "( 1  ,2047,.,.) = \n",
       "  0.1581\n",
       "        ⋮  \n",
       "\n",
       "( 2  , 0  ,.,.) = \n",
       "  0.1761\n",
       "\n",
       "( 2  , 1  ,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 2  , 2  ,.,.) = \n",
       "  0.0087\n",
       "      ... \n",
       "\n",
       "( 2  ,2045,.,.) = \n",
       "  0.6109\n",
       "\n",
       "( 2  ,2046,.,.) = \n",
       "  0.2367\n",
       "\n",
       "( 2  ,2047,.,.) = \n",
       "  0.0000\n",
       " ...      \n",
       "        ⋮  \n",
       "\n",
       "( 7  , 0  ,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 7  , 1  ,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 7  , 2  ,.,.) = \n",
       "  0.0000\n",
       "      ... \n",
       "\n",
       "( 7  ,2045,.,.) = \n",
       "  0.6202\n",
       "\n",
       "( 7  ,2046,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 7  ,2047,.,.) = \n",
       "  0.0317\n",
       "        ⋮  \n",
       "\n",
       "( 8  , 0  ,.,.) = \n",
       "  0.0432\n",
       "\n",
       "( 8  , 1  ,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 8  , 2  ,.,.) = \n",
       "  0.0000\n",
       "      ... \n",
       "\n",
       "( 8  ,2045,.,.) = \n",
       "  0.0617\n",
       "\n",
       "( 8  ,2046,.,.) = \n",
       "  0.0672\n",
       "\n",
       "( 8  ,2047,.,.) = \n",
       "  0.0000\n",
       "        ⋮  \n",
       "\n",
       "( 9  , 0  ,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 9  , 1  ,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 9  , 2  ,.,.) = \n",
       "  0.0000\n",
       "      ... \n",
       "\n",
       "( 9  ,2045,.,.) = \n",
       "  0.2144\n",
       "\n",
       "( 9  ,2046,.,.) = \n",
       "  0.0000\n",
       "\n",
       "( 9  ,2047,.,.) = \n",
       "  0.0000\n",
       "[torch.FloatTensor of size 10x2048x1x1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = Model().forward(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat received an invalid combination of arguments - got (torch.LongTensor, torch.LongTensor, int), but expected one of:\n * (sequence[torch.LongTensor] seq)\n * (sequence[torch.LongTensor] seq, int dim)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ef155336053f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cat received an invalid combination of arguments - got (torch.LongTensor, torch.LongTensor, int), but expected one of:\n * (sequence[torch.LongTensor] seq)\n * (sequence[torch.LongTensor] seq, int dim)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = torch.cat(a, b, 2)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  5  0\n",
       " 3  0  3\n",
       "[torch.LongTensor of size 2x3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [[0, 5, 0],[3, 0, 3]]\n",
    "a = (torch.LongTensor(np.array(l)))\n",
    "\n",
    "# a = torch.randn(4, 3, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Variable( a ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1], [1], [1]]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [[] for _ in range(3)]\n",
    "c\n",
    "d = [[[1]]*3]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.view((3, -1))\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.softmax(a, dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
